# -*- coding: utf-8 -*-
"""resnet_tinyimagesetv2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ryknwxwOhnLI69vsnxP90MtAEJdMhwCc
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip
!unzip -qq 'tiny-imagenet-200.zip'

import os
import torch

def create_val_folder(val_dir):
  '''
  This method is responsible for separating validation
  images into separate sub folders
  '''
  # path where validation data is present now
  path = os.path.join(
      val_dir, 'images')
  # file where image2class mapping is present
  filename = os.path.join(val_dir, 'val_annotations.txt')
  fp = open(filename, "r") # open file in read mode
  data = fp.readlines() # read line by line
  '''
  Create a dictionary with image names as key and
  corresponding classes as values
  '''

  val_img_dict = {}
  for line in data:
      words = line.split("\t")
      val_img_dict[words[0]] = words[1]
      fp.close()
  # Create folder if not present, and move image into proper folder
  for img, folder in val_img_dict.items():
      newpath = (os.path.join(path, folder))
      if not os.path.exists(newpath): # check if folder exists
        os.makedirs(newpath)
  # Check if image exists in default directory
      if os.path.exists(os.path.join(path, img)):
        os.rename(os.path.join(path, img), os.path.join(newpath, img))
  return

import torchvision.datasets as datasets
import torchvision.transforms as transforms


#Initialize
transform_train = transforms.Compose([
    transforms.RandomCrop(64, padding = 4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor()
])
 
transform_test = transforms.Compose([
    transforms.ToTensor()
])

batch_size = 128

train_dir =  'tiny-imagenet-200/train/'#'/u/training/tra207/scratch/hwk4/datasets/tiny-imagenet-200/train/' #
train_dataset = datasets.ImageFolder(train_dir,transform=transform_train)
#print(train_dataset.class_to_idx)

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)
val_dir = 'tiny-imagenet-200/val/' #'/u/training/tra207/scratch/hwk4/datasets/tiny-imagenet-200/val/' #
if 'val_' in os.listdir(val_dir+'images/')[0]:
    create_val_folder(val_dir)
    val_dir = val_dir+'images/'
else:
    val_dir = val_dir+'images/'

val_dataset = datasets.ImageFolder(val_dir, transform=transform_test)
#print(val_dataset.class_to_idx)

val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

#resnet module

import torch.nn as nn



def conv3x3(in_channels, out_channels, stride = 1):
    return nn.Conv2d(in_channels = in_channels, out_channels = out_channels,
                   kernel_size =3, stride = stride, padding = 1, bias = False)

class BasicBlock(nn.Module):
      
  
  def __init__(self, in_channels, out_channels, stride = 1, downsample = None):
    super(BasicBlock, self).__init__()
    
    self.conv1 = conv3x3(in_channels, out_channels, stride)
    self.bn1 = nn.BatchNorm2d(out_channels)
    self.relu = nn.ReLU(inplace = True)
    
    self.conv2 =conv3x3(out_channels, out_channels)
    self.bn2 = nn.BatchNorm2d(out_channels)
    self.relu = nn.ReLU(inplace = True)
    
    self.downsample= downsample
    self.stride = stride
    
  def forward(self,x):
    residual = x
    output = self.conv1(x)
    output = self.bn1(output)
    output = self.relu(output)
    
    output = self.conv2(output)
    output = self.bn2(output)

    
    if self.downsample is not None:
      residual = self.downsample(x)
    output += residual
    output = self.relu(output)
    return output

class ResNet(nn.Module):
  
  
  def __init__(self, block, dup_blocks, num_classes):
    
    super(ResNet, self).__init__()
    
    self.conv1 = conv3x3(in_channels = 3, out_channels = 32)
    #self.in_channels = 32
    self.bn1 = nn.BatchNorm2d(num_features = 32)
    self.relu = nn.ReLU(inplace = True)
    self.dropout = nn.Dropout2d(p = 0.1)
    
    self.conv2_x = self._make_layer(block, dup_blocks[0], in_channels = 32, out_channels = 32)
    self.conv3_x = self._make_layer(block, dup_blocks[1], in_channels = 32, out_channels = 64, stride = 2)
    self.conv4_x = self._make_layer(block, dup_blocks[2], in_channels = 64, out_channels = 128, stride = 2)
    self.conv5_x = self._make_layer(block, dup_blocks[3], in_channels = 128, out_channels = 256, stride = 2) 
    self.maxpool = nn.MaxPool2d(kernel_size = 4, stride = 4)
    self.conv6 = conv3x3(in_channels = 256, out_channels = 512)
    self.bn2 = nn.BatchNorm2d(num_features = 512)
    self.relu = nn.ReLU(inplace = True)
        
    self.fc_layer1 = nn.Linear(512 * 4, 512)
    self.relu = nn.ReLU(inplace= True)
    self.fc_layer2 = nn.Linear(512, num_classes)
    
    
  def _make_layer(self, block, dup_blocks, in_channels, out_channels, stride = 1):
    
    downsample = None
    if (stride != 1) or (in_channels != out_channels):
          downsample = nn.Sequential(
              conv3x3(in_channels, out_channels, stride = stride),
              nn.BatchNorm2d(num_features = out_channels))
          
    layers = []
    layers.append(block(in_channels, out_channels, stride, downsample))
        
    for _ in range(1, dup_blocks):
      layers.append(block(out_channels, out_channels))

    return nn.Sequential(*layers)
      
  def forward(self,x):

    output = self.conv1(x)
    output = self.bn1(output)
    output = self.relu(output)
    output = self.dropout(output)
    
    output = self.conv2_x(output)
    output = self.conv3_x(output)
    output = self.conv4_x(output)
    output = self.conv5_x(output)
    output = self.maxpool(output)
    output = self.conv6(output)
    output = self.bn2(output)
    output = self.relu(output)
    
    
    output = output.view(output.size(0),-1)
    output = self.fc_layer1(output)
    output = self.relu(output)
    output = self.fc_layer2(output)
    return output

#utils module
import torchvision
import torch.utils.data
import torchvision.transforms as transforms
import numpy as np
import time


def calculate_accuracy(net, loader):
    correct = 0
    total = 0
    net.eval()
    with torch.no_grad():
      for (images, labels) in loader:
          device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
          images = images.to(device)
          labels = labels.to(device)

          outputs = net(images)
          _, predicted = torch.max(outputs.data,1)
          total += labels.size(0)
          correct += (predicted==labels).sum()
    
    net.train()
    return (100.0*correct/total)

  
def train(net, criterion, optimizer, trainloader, testloader, epochs):
    print("Training in progress...")
    log_avg_loss = []
    log_epoch = []
    log_train_accuracy = []
    log_test_accuracy = []
    
    for epoch in range (epochs):
        start = time.time()
        net.train()
        running_loss = 0.0
        
        batch_start = time.time() #Batch Start timer initialized
        for batch_indx, (images, labels) in enumerate(trainloader):
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            images = images.to(device)
            labels = labels.to(device)

            outputs = net(images)
            loss = criterion(outputs, labels)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            if(batch_indx+1)% 100 == 0:
              batch_end = time.time() #Batch end timer
              print("[{0}/{1}]: Average Loss = {2} | Time Elapsed = {3} min".format(batch_indx+1, len(trainloader), running_loss/(batch_indx+1), 
                                                                                   (batch_end - batch_start)/60))
              batch_start = time.time()#restting Batch timer
                                 
        scheduler.step(loss)
        avg_loss= running_loss/len(trainloader)
        train_accuracy = calculate_accuracy(net, trainloader)
        test_accuracy = calculate_accuracy(net, testloader)
        
        log_epoch.append(epoch+1)
        log_avg_loss.append(avg_loss)
        log_train_accuracy.append(train_accuracy)
        log_test_accuracy.append(test_accuracy)
        
        end = time.time()
        print ("Epoch: {0} || Loss: {1} || Training Accuracy: {2}%  ||  Testing Accuracy: {3}% || Time Elapsed: {4}".format(
            epoch+1, avg_loss, train_accuracy, test_accuracy, (end-start)/60))
        
        #FOR DEBUGGING TESTING
        print("This is for testing purposes\n\n",
              "epoch:", log_epoch,
              "\navg_loss:", log_avg_loss, 
              "\nlog_train_accuracy:", log_train_accuracy, 
              "\nlog_test_accuracy:", log_test_accuracy)

        
        
        
            
    print("Training Completed!")
    return(log_epoch, log_avg_loss, log_train_accuracy, log_test_accuracy)

lr = 0.01
momentum= 0.9
weight_decay = 1e-5
step_size = 3
gamma = 0.1
epochs = 50
num_classes = 200
dup_blocks = [2,4,4,2]



net = ResNet(BasicBlock, dup_blocks, num_classes)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
net = net.to(device)

# Loss function, optimizer and scheduler
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(net.parameters(),
                             lr=lr,
                             momentum=momentum,
                             weight_decay=weight_decay)

#optimizer = torch.optim.Adam(net.parameters(), 
#                       lr = lr, 
#                       weight_decay=1e-5)
# scheduler = torch.optim.lr_scheduler.StepLR(optimizer,
#                                        step_size = step_size,
#                                        gamma = gamma)

scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1, verbose=True)


# training
epoch, loss, train_ac, test_ac = train(net, criterion, optimizer, train_loader, val_loader, epochs)

import pandas as pd

df = pd.DataFrame()
df['epoch'] = epoch
df['loss'] = loss
df['train_ac'] = train_ac
df['test_ac'] = test_ac

import matplotlib.pyplot as plt
import seaborn as sns

for i in ['loss', 'train_ac', 'test_ac']:
  plt.plot('epoch', i, data = df, linestyle = '-', marker = 'o', label = i)
  
plt.legend(shadow=True, fontsize='x-large')
plt.show()

torch.cuda.is_available()

