# -*- coding: utf-8 -*-
"""resnet_pretrained_cifar100v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FQW2IjavsjbHQrEze39ldsPm7ewx4Vqe
"""

import torch
import torch.nn as nn
import torchvision
import torch.utils.data
import torchvision.transforms as transforms
import time

def data_loader(dataroot, batch_size_train, batch_size_test):
    transform_train = transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
    ])

    transform_test = transforms.Compose([
        transforms.Resize(224),
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
    ])

    trainset = torchvision.datasets.CIFAR100(root=dataroot,
                                             train=True,
                                             download=True,
                                             transform=transform_train)
    trainloader = torch.utils.data.DataLoader(
        trainset, batch_size=batch_size_train, shuffle=True, num_workers=4)

    testset = torchvision.datasets.CIFAR100(root=dataroot,
                                            train=False,
                                            download=True,
                                            transform=transform_test)
    testloader = torch.utils.data.DataLoader(
        testset, batch_size=batch_size_test, shuffle=False, num_workers=4)

    return trainloader, testloader

def calculate_accuracy(net, loader):
    correct = 0
    total = 0
    net.eval()
    with torch.no_grad():
      for (images, labels) in loader:
          device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
          images = images.to(device)
          labels = labels.to(device)

          outputs = net(images)
          _, predicted = torch.max(outputs.data,1)
          total += labels.size(0)
          correct += (predicted==labels).sum()
    
    net.train()
    return (100.0*correct/total)

  
def train(net, criterion, optimizer, trainloader, testloader, epochs):
    print("Training in progress...")
    log_avg_loss = []
    log_epoch = []
    log_train_accuracy = []
    log_test_accuracy = []
    
    for epoch in range (epochs):
        start = time.time()
        net.train()
        running_loss = 0.0
        
        batch_start = time.time() #Batch Start timer initialized
        for batch_indx, (images, labels) in enumerate(trainloader):
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            images = images.to(device)
            labels = labels.to(device)

            outputs = net(images)
            loss = criterion(outputs, labels)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            if(batch_indx+1)% 100 == 0:
              batch_end = time.time() #Batch end timer
              print("[{0}/{1}]: Average Loss = {2} | Time Elapsed = {3} min".format(batch_indx+1, len(trainloader), running_loss/(batch_indx+1), 
                                                                                   (batch_end - batch_start)/60))
              batch_start = time.time()#restting Batch timer
                                 
        scheduler.step(loss)
        avg_loss= running_loss/len(trainloader)
        train_accuracy = calculate_accuracy(net, trainloader)
        test_accuracy = calculate_accuracy(net, testloader)
        
        log_epoch.append(epoch+1)
        log_avg_loss.append(avg_loss)
        log_train_accuracy.append(train_accuracy)
        log_test_accuracy.append(test_accuracy)
        
        end = time.time()
        print ("Epoch: {0} || Loss: {1} || Training Accuracy: {2}%  ||  Testing Accuracy: {3}% || Time Elapsed: {4}".format(
            epoch+1, avg_loss, train_accuracy, test_accuracy, (end-start)/60))
        
        #FOR DEBUGGING TESTING
        print("This is for testing purposes\n\n",
              "epoch:", log_epoch,
              "\navg_loss:", log_avg_loss, 
              "\nlog_train_accuracy:", log_train_accuracy, 
              "\nlog_test_accuracy:", log_test_accuracy)
        
        
        
            
    print("Training Completed!")
    return(log_epoch, log_avg_loss, log_train_accuracy, log_test_accuracy)

lr = 0.01
momentum= 0.9
weight_decay = 0
#step_size = 10
#gamma = 0.1
epochs = 50
num_classes = 100
#dup_blocks = [2,4,4,2]
batch_size = 32
dataroot = './data'

# load data
train_loader, test_loader = data_loader(dataroot, batch_size, batch_size)

# load model
model = torchvision.models.resnet18(pretrained=True)
net = model
device = torch.device('cuda' if torch.cuda.is_available() == True  else 'cpu')
fc_inp=model.fc.in_features
num_ftrs = net.fc.in_features
net.fc = nn.Linear(num_ftrs, 100)
net = net.to(device)


# Loss function, optimizer and scheduler
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(net.parameters(),
                             lr=lr,
                             momentum=momentum,
                             weight_decay=weight_decay)

#optimizer = torch.optim.Adam(net.parameters(), 
#                       lr = lr, 
#                       weight_decay=1e-5)
#scheduler = torch.optim.lr_scheduler.StepLR(optimizer,
#                                       step_size = step_size,
#                                       gamma = gamma)

# Scheduler
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, verbose=True)



# training
epoch, loss, train_ac, test_ac = train(net, criterion, optimizer, train_loader, test_loader, epochs)

import pandas as pd

df = pd.DataFrame()
df['epoch'] = epoch
df['loss'] = loss
df['train_ac'] = train_ac
df['test_ac'] = test_ac

import matplotlib.pyplot as plt
import seaborn as sns

for i in ['loss', 'train_ac', 'test_ac']:
  plt.plot('epoch', i, data = df, linestyle = '-', marker = 'o', label = i)
  
plt.legend(shadow=True, fontsize='x-large')
plt.show()